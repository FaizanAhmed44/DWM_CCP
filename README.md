# Heart Disease Analytics Data Warehouse
**Course**: Data Warehouse Mining (CT-463) - Lab Session 12  
**Institution**: NED University of Engineering and Technology  
**Department**: Computer Science and Information Technology

## üéØ Project Overview

This project implements a comprehensive data warehouse solution for heart disease analytics, integrating multiple heterogeneous data sources into a unified Star Schema-based analytical system. The warehouse enables healthcare organizations to perform advanced analytics, predict patient risks, and optimize resource allocation.

## üìã Table of Contents
1. [Business Problem](#business-problem)
2. [Architecture](#architecture)
3. [Data Sources](#data-sources)
4. [Star Schema Design](#star-schema-design)
5. [ETL Pipeline](#etl-pipeline)
6. [Data Quality Framework](#data-quality-framework)
7. [Machine Learning Integration](#machine-learning-integration)
8. [Installation & Setup](#installation--setup)
9. [Key Performance Indicators](#key-performance-indicators)
10. [Technologies Used](#technologies-used)

---

## üè• Business Problem

Healthcare organizations struggle with:
- **Fragmented Data**: Patient records scattered across HMS, EHR, and lab systems
- **Delayed Insights**: Manual reporting takes 48+ hours
- **Risk Identification**: No predictive system for high-risk patients
- **Cost Optimization**: Unclear treatment cost patterns by disease severity
- **Hospital Performance**: No standardized benchmarking across facilities

**Solution**: A centralized data warehouse with ML-powered risk prediction and real-time BI dashboards.

---

## üèóÔ∏è Architecture
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    DATA SOURCES                              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  OLTP 1: HMS         OLTP 2: EHR         API: Labs          ‚îÇ
‚îÇ  (Prisma ORM)        (Prisma ORM)        (REST API)         ‚îÇ
‚îÇ  520 Patients        1,345 Visits        500 Tests          ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  Flat File: Disease Reference (CSV)                         ‚îÇ
‚îÇ  3 ICD-10 Codes with Treatment Guidelines                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   ETL PIPELINE                               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Extract ‚Üí Transform ‚Üí Load                                  ‚îÇ
‚îÇ  ‚Ä¢ Data Type Conversion   ‚Ä¢ Deduplication                    ‚îÇ
‚îÇ  ‚Ä¢ Datetime Normalization ‚Ä¢ Derived Metrics                  ‚îÇ
‚îÇ  ‚Ä¢ Risk Scoring           ‚Ä¢ Star Schema Mapping              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            GOOGLE BIGQUERY DATA WAREHOUSE                    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Star Schema: 4 Dimensions + 2 Fact Tables                   ‚îÇ
‚îÇ  ‚Ä¢ dim_patient        ‚Ä¢ dim_hospital                         ‚îÇ
‚îÇ  ‚Ä¢ dim_date          ‚Ä¢ dim_disease                           ‚îÇ
‚îÇ  ‚Ä¢ fact_visits       ‚Ä¢ fact_labs                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              ANALYTICS & VISUALIZATION                        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ML Models:           BI Dashboards:                         ‚îÇ
‚îÇ  ‚Ä¢ Logistic Regression ‚Ä¢ Interactive HTML                    ‚îÇ
‚îÇ  ‚Ä¢ KMeans Clustering   ‚Ä¢ 6 KPI Cards                         ‚îÇ
‚îÇ  ‚Ä¢ Risk Prediction     ‚Ä¢ Plotly Charts                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìä Data Sources

### 1. **OLTP System 1: Hospital Management System (HMS)**
- **Technology**: Prisma ORM connected to PostgreSQL
- **Endpoint**: `http://localhost:3000/api/hms-patients`
- **Records**: 520 patients
- **Data Generation**: LLM-generated synthetic data with realistic distributions
- **Key Fields**: 
  - Demographics: age, gender, blood_type, city, province
  - Clinical: BMI, smoker, diabetic, family_history_heart_disease
  - Insurance: insurance_provider

### 2. **OLTP System 2: Electronic Health Records (EHR)**
- **Technology**: Prisma ORM REST API
- **Endpoint**: `http://localhost:3000/api/ehr-visits`
- **Records**: 1,345 hospital visits
- **Key Fields**:
  - Vitals: systolic_bp, diastolic_bp, heart_rate
  - Labs: cholesterol, blood_sugar
  - Diagnosis: heart_disease_diagnosed, diagnosis_severity, treatment_plan

### 3. **API: Laboratory Information System**
- **Endpoint**: `http://localhost:3000/api/lab-results`
- **Records**: 500 lab tests
- **Test Types**: 
  - Lipid Profile, Cardiac Enzymes, CRP Test, BNP Test
  - HbA1c, Thyroid Function, Electrolyte Panel
- **Key Fields**: LDL, HDL, triglycerides, CRP, HbA1c

### 4. **Flat File: Disease Reference Database**
- **Format**: CSV (`source_heart_disease_ref.csv`)
- **Records**: 3 ICD-10 coded diseases
- **Content**:
  - ICD Codes: I21.0, I25.1, I50.0
  - Disease Names: Myocardial Infarction, Coronary Artery Disease, Heart Failure
  - Treatment Guidelines, Mortality Rates, Average Costs

### 5. **Hospital Metadata API**
- **Endpoint**: `http://localhost:3000/api/hospitals`
- **Records**: 12 major cardiac centers in Pakistan
- **Key Fields**:
  - Facilities: cardiac_beds, cardiac_surgery_available, cath_lab
  - Performance: angioplasty_success_rate, bypass_success_rate
  - Capacity: annual_heart_surgeries, cardiac_doctors_count

---

## ‚≠ê Star Schema Design

### **Dimensional Model**
```
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   dim_patient   ‚îÇ
                    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ
                    ‚îÇ patient_key (PK)‚îÇ
                    ‚îÇ national_id     ‚îÇ
                    ‚îÇ age, bmi        ‚îÇ
                    ‚îÇ high_risk       ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
                             ‚îÇ 1:N
                             ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ dim_hospital ‚îÇ    ‚îÇ  fact_visits    ‚îÇ    ‚îÇ  dim_date    ‚îÇ
‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ
‚îÇhospital_key  ‚îÇ‚ÜêN:1‚îÇ patient_key (FK)‚îÇ1:N‚Üí‚îÇ date_key (PK)‚îÇ
‚îÇhospital_name ‚îÇ    ‚îÇ hospital_key(FK)‚îÇ    ‚îÇ full_date    ‚îÇ
‚îÇsuccess_rate  ‚îÇ    ‚îÇ date_key (FK)   ‚îÇ    ‚îÇ year, month  ‚îÇ
‚îÇtier          ‚îÇ    ‚îÇ disease_key (FK)‚îÇ    ‚îÇ quarter      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ vitals, diagnosis‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ 1:N
                             ‚Üì
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ  dim_disease    ‚îÇ
                    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ
                    ‚îÇdisease_key (PK) ‚îÇ
                    ‚îÇ icd_code        ‚îÇ
                    ‚îÇ disease_name    ‚îÇ
                    ‚îÇ mortality_rate  ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   fact_labs     ‚îÇ
                    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ
                    ‚îÇ date_key (FK)   ‚îÇ
                    ‚îÇ test_type       ‚îÇ
                    ‚îÇ cholesterol     ‚îÇ
                    ‚îÇ hba1c, crp      ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### **Dimension Tables**

#### 1. `dim_patient` (520 rows)
```sql
CREATE TABLE dim_patient (
    patient_key INT PRIMARY KEY,
    patient_national_id STRING,
    age INT,
    gender STRING,
    date_of_birth DATE,
    city STRING,
    province STRING,
    blood_type STRING,
    insurance_provider STRING,
    smoker BOOLEAN,
    diabetic BOOLEAN,
    family_history_heart_disease BOOLEAN,
    bmi FLOAT,
    high_risk INT,           -- Computed: 1 if ‚â•1 risk factors
    age_group STRING         -- Young/Middle/Senior
);
```

#### 2. `dim_hospital` (12 rows)
```sql
CREATE TABLE dim_hospital (
    hospital_key INT PRIMARY KEY,
    hospitalId STRING,
    hospitalName STRING,
    city STRING,
    province STRING,
    specialization STRING,
    cardiacSurgeryAvailable BOOLEAN,
    cathLabAvailable BOOLEAN,
    cardiacBeds INT,
    annualHeartSurgeries INT,
    angioplastySuccessRate FLOAT,
    bypassSurgerySuccessRate FLOAT,
    avgHeartTreatmentCost FLOAT,
    cardiacDoctorsCount INT,
    capability_score INT,    -- Computed: facility rating
    tier STRING              -- Tier 1/2/3
);
```

#### 3. `dim_date` (2,557 rows: 2020-2026)
```sql
CREATE TABLE dim_date (
    date_key INT PRIMARY KEY,
    full_date DATE,
    year INT,
    month INT,
    day INT,
    quarter INT,
    day_of_week STRING
);
```

#### 4. `dim_disease` (3 rows)
```sql
CREATE TABLE dim_disease (
    disease_key INT PRIMARY KEY,
    icd_code STRING,              -- I21.0, I25.1, I50.0
    disease_name STRING,          -- MI, CAD, Heart Failure
    risk_factors TEXT,
    diagnostic_criteria TEXT,
    treatment_guideline TEXT,
    mortality_rate FLOAT,
    avg_treatment_cost FLOAT
);
```

### **Fact Tables**

#### 1. `fact_visits` (1,345 rows)
```sql
CREATE TABLE fact_visits (
    patient_key INT,              -- FK to dim_patient
    hospital_key INT,             -- FK to dim_hospital
    date_key INT,                 -- FK to dim_date
    disease_key INT,              -- FK to dim_disease (implicit via diagnosis_severity)
    department STRING,
    doctor_id STRING,
    systolic_bp INT,
    diastolic_bp INT,
    heart_rate INT,
    cholesterol INT,
    blood_sugar INT,
    heart_disease_diagnosed BOOLEAN,
    diagnosis_severity STRING,    -- Mild/Moderate/Severe (maps to disease_key)
    treatment_plan STRING,
    hypertension INT,             -- Computed: BP ‚â• 140/90
    high_cholesterol INT,         -- Computed: cholesterol > 200
    diagnosis_year INT,
    diagnosis_month INT
);
```

**Disease Linkage Strategy**: 
- `diagnosis_severity` serves as an implicit foreign key mapping:
  - "Mild" ‚Üí disease_key 1 (Early CAD)
  - "Moderate" ‚Üí disease_key 2 (Angina/CAD)
  - "Severe" ‚Üí disease_key 3 (MI/Heart Failure)
- This design allows risk stratification aligned with clinical severity levels

#### 2. `fact_labs` (500 rows)
```sql
CREATE TABLE fact_labs (
    date_key INT,                 -- FK to dim_date
    testType STRING,
    ldlCholesterol FLOAT,
    hdlCholesterol FLOAT,
    triglycerides FLOAT,
    totalCholesterol FLOAT,
    crpLevel FLOAT,
    fastingBloodSugar FLOAT,
    hba1c FLOAT,
    resultStatus STRING,
    ldl_risk STRING,              -- High/Normal
    hdl_risk STRING,              -- Low/Normal
    hba1c_risk STRING             -- Normal/Prediabetes/Diabetes
);
```

---

## üîÑ ETL Pipeline

### **Phase 1: Extract**
```python
def fetch_api_data(url, name="data"):
    """Extracts data from Prisma ORM REST APIs"""
    response = requests.get(url, timeout=15)
    data = response.json()
    # Handle nested JSON responses from Prisma
    if isinstance(data, dict):
        for v in data.values():
            if isinstance(v, list) and v and isinstance(v[0], dict):
                return pd.DataFrame(v)
    return pd.DataFrame(data)
```

**Data Volumes Extracted**:
- HMS Patients: 520 records
- EHR Visits: 1,345 records
- Lab Results: 500 records
- Hospitals: 12 records
- Disease Reference: 3 records (CSV)

### **Phase 2: Transform**

#### **Data Type Conversions**
```python
# Numeric conversions with error handling
patients['age'] = pd.to_numeric(patients['age'], errors='coerce')
patients['bmi'] = pd.to_numeric(patients['bmi'], errors='coerce')

# Datetime standardization
patients['created_timestamp'] = pd.to_datetime(patients['created_timestamp'], errors='coerce')
ehr_visits['visit_datetime'] = pd.to_datetime(ehr_visits['visit_datetime'], errors='coerce')

# Boolean conversions
hospitals['cardiacSurgeryAvailable'] = hospitals['cardiacSurgeryAvailable'].astype(bool)
```

#### **Derived Metrics & Business Rules**

**1. Patient Risk Score**:
```python
patients['high_risk'] = (
    (patients['age'] >= 60).astype(int) +
    (patients['bmi'] >= 30).astype(int) +
    patients['smoker'].astype(int) +
    patients['diabetic'].astype(int) +
    patients['family_history_heart_disease'].astype(int)
)
patients['high_risk'] = (patients['high_risk'] >= 1).astype(int)
```

**2. Hospital Capability Scoring**:
```python
score = (
    hospitals['cardiacSurgeryAvailable'].astype(int) * 3 +
    hospitals['cathLabAvailable'].astype(int) * 2 +
    (hospitals['cardiacBeds'] > 100).astype(int) +
    (hospitals['angioplastySuccessRate'] >= 95).astype(int) * 2
)
hospitals['tier'] = pd.cut(score, bins=[0,3,6,8], labels=['Tier 3','Tier 2','Tier 1'])
```

**3. Lab Risk Categories**:
```python
lab_results['ldl_risk'] = np.where(lab_results['ldlCholesterol'] > 130, 'High', 'Normal')
lab_results['hba1c_risk'] = pd.cut(
    lab_results['hba1c'], 
    bins=[0, 5.7, 6.5, 20], 
    labels=['Normal', 'Prediabetes', 'Diabetes']
)
```

**4. Visit-Level Clinical Flags**:
```python
ehr_visits['hypertension'] = (
    (ehr_visits['systolic_bp'] >= 140) | 
    (ehr_visits['diastolic_bp'] >= 90)
).astype(int)
ehr_visits['high_cholesterol'] = (ehr_visits['cholesterol'] > 200).astype(int)
```

#### **Critical Fix: Timezone Normalization**
```python
# Convert timezone-aware datetime to naive before joining with dim_date
fv['visit_date'] = fv['visit_datetime'].dt.tz_localize(None).dt.normalize()
```
This prevented join failures between fact tables and the date dimension.

### **Phase 3: Load**
```python
def load_to_bq(df, table_name):
    """Loads DataFrame to BigQuery with WRITE_TRUNCATE"""
    table_ref = dataset_ref.table(table_name)
    job_config = bigquery.LoadJobConfig(write_disposition="WRITE_TRUNCATE")
    job = client.load_table_from_dataframe(df, table_ref, job_config=job_config)
    job.result()
```

**Loading Sequence**:
1. Dimensions first (patient, hospital, date, disease)
2. Facts second (visits, labs)
3. Ensures referential integrity

---

## ‚úÖ Data Quality Framework

### **1. Null Key Validation**
```sql
-- Zero null keys in fact tables
SELECT 'fact_visits' AS table_name, COUNT(*) AS null_keys
FROM `dwm-ccp-478012.heart_disease_warehouse.fact_visits`
WHERE date_key IS NULL OR patient_key IS NULL OR hospital_key IS NULL
-- Result: 0 null keys
```

### **2. Join Integrity Check**
```sql
-- All 1,345 visits have valid foreign keys
SELECT 
  COUNT(*) AS total_visits,
  COUNT(patient_key) AS with_patient,
  COUNT(hospital_key) AS with_hospital,
  COUNT(date_key) AS with_date
FROM `fact_visits`
-- Result: 1345, 1345, 1345, 1345
```

### **3. Duplicate Detection**
```python
# Check for duplicate patient records
duplicates = df[df.duplicated(subset=['patient_national_id'], keep=False)]
print(f"Duplicate records: {len(duplicates)}")
# Removed 3 duplicate records
```

### **4. Outlier Detection (IQR Method)**
```python
Q1 = df['cholesterol'].quantile(0.25)
Q3 = df['cholesterol'].quantile(0.75)
IQR = Q3 - Q1
outliers = df[(df['cholesterol'] < Q1 - 1.5*IQR) | (df['cholesterol'] > Q3 + 1.5*IQR)]
# Flagged 8 cholesterol outliers for review
```

### **5. Lab Test Coverage**
```sql
-- Ensure all 8 lab test types have date linkage
SELECT testType, COUNT(*) AS count, COUNT(date_key) AS with_date
FROM `fact_labs`
GROUP BY testType
-- All 500 tests have valid date_key
```

---

## ü§ñ Machine Learning Integration

### **1. Logistic Regression - Risk Prediction**

**Objective**: Predict heart disease diagnosis probability

**Features**:
```python
features = [
    'age', 'bmi', 
    'systolic_bp', 'diastolic_bp', 'cholesterol',
    'smoker', 'diabetic', 'family_history_heart_disease'
]
```

**Model Training**:
```python
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler

X = df[features].fillna(0)
y = df['heart_disease_diagnosed'].astype(int)

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

clf = LogisticRegression(max_iter=1000)
clf.fit(X_scaled, y)

# Generate risk scores
df['risk_score'] = (clf.predict_proba(X_scaled)[:, 1] * 100).round(1)
```

**Performance**:
- Accuracy: 100% (on training data)
- Precision/Recall: High across all classes
- Feature Importance: Cholesterol (2.95), Systolic BP (2.93), Diastolic BP (2.88)

**Business Application**:
- Doctors prioritize patients with risk_score > 70%
- Insurance premiums adjusted based on ML predictions
- Hospital resources allocated to high-risk clusters

### **2. KMeans Clustering - Patient Segmentation**

**Objective**: Segment patients into risk groups
```python
from sklearn.cluster import KMeans

kmeans = KMeans(n_clusters=3, random_state=42)
df['cluster'] = kmeans.fit_predict(X_scaled)
df['risk_level'] = df['cluster'].map({
    0: 'Low Risk', 
    1: 'Medium Risk', 
    2: 'High Risk'
})
```

**Results**:
- **Medium Risk**: 650 patients (48.3%) - Routine monitoring
- **High Risk**: 387 patients (28.8%) - Intensive care protocols
- **Low Risk**: 308 patients (22.9%) - Standard preventive care

**Clinical Decision Support**:
| Risk Level | Intervention Strategy |
|------------|----------------------|
| Low Risk | Annual checkup, lifestyle counseling |
| Medium Risk | Quarterly monitoring, medication review |
| High Risk | Monthly visits, aggressive treatment, specialist referral |

### **3. Anomaly Detection - Fraud/Error Detection**
```python
from sklearn.ensemble import IsolationForest

iso_forest = IsolationForest(contamination=0.05, random_state=42)
df['anomaly'] = iso_forest.fit_predict(X_scaled)
anomalies = df[df['anomaly'] == -1]

# Detected 67 anomalous records for review
```

**Use Cases**:
- Detect fraudulent insurance claims (abnormal cost + low severity)
- Identify data entry errors (age=200, cholesterol=900)
- Flag unusual treatment patterns for audit

---

## üìà Key Performance Indicators (KPIs)

### **Dashboard Overview**

| KPI | Value | Formula | Business Impact |
|-----|-------|---------|----------------|
| **Diagnosis Rate** | 51.8% | (Diagnosed / Total Visits) √ó 100 | High rate indicates effective screening |
| **High-Risk Patient %** | 28.8% | (Cluster 2 / Total Patients) √ó 100 | Resource allocation priority |
| **Top Hospital Success** | 96.5% | max(angioplasty_success_rate) | Benchmarking standard |
| **Avg Cost (Severe)** | $18,000 | avg(cost WHERE severity='Severe') | Budget planning |
| **Lab Abnormal Rate** | 45.2% | (Abnormal Tests / Total) √ó 100 | Early intervention trigger |
| **ML Predicted Risk** | 62.7% | avg(risk_score) | Population health metric |

### **SQL Queries for KPIs**

#### KPI 1: High-Risk Diagnosis Rate
```sql
WITH diag AS (
  SELECT 
    COUNTIF(p.high_risk = 1 AND v.heart_disease_diagnosed = true) AS high_risk_dx,
    COUNT(*) AS total
  FROM `fact_visits` v
  JOIN `dim_patient` p ON v.patient_key = p.patient_key
)
SELECT ROUND(high_risk_dx * 100.0 / total, 1) AS high_risk_diagnosis_rate
FROM diag;
-- Result: 51.6%
```

#### KPI 2: Hospital Performance Ranking
```sql
SELECT 
  h.hospitalName,
  ROUND(AVG(CASE WHEN v.heart_disease_diagnosed THEN 1 ELSE 0 END) * 100, 1) AS diagnosis_rate,
  h.angioplastySuccessRate,
  h.tier
FROM `fact_visits` v
JOIN `dim_hospital` h ON v.hospital_key = h.hospital_key
GROUP BY h.hospitalName, h.angioplastySuccessRate, h.tier
ORDER BY diagnosis_rate DESC
LIMIT 10;
```

#### KPI 3: Disease Severity Distribution (Linked to dim_disease)
```sql
SELECT 
  v.diagnosis_severity,
  COUNT(*) AS case_count,
  ROUND(AVG(v.systolic_bp), 1) AS avg_bp,
  -- Implicit mapping to dim_disease via severity levels
  CASE v.diagnosis_severity
    WHEN 'Mild' THEN 'I25.1 (Early CAD)'
    WHEN 'Moderate' THEN 'I25.1 (Stable CAD)'
    WHEN 'Severe' THEN 'I21.0 (Acute MI)'
  END AS disease_classification
FROM `fact_visits` v
WHERE v.heart_disease_diagnosed = true
GROUP BY v.diagnosis_severity
ORDER BY 
  CASE v.diagnosis_severity 
    WHEN 'Severe' THEN 1 
    WHEN 'Moderate' THEN 2 
    ELSE 3 
  END;
```

---

## üíª Installation & Setup

### **Prerequisites**
```bash
# Required Software
- Python 3.8+
- Node.js 16+ (for Prisma ORM)
- Google Cloud SDK
- BigQuery Account
```

### **Step 1: Clone Repository**
```bash
git clone https://github.com/yourusername/heart-disease-warehouse.git
cd heart-disease-warehouse
```

### **Step 2: Set Up Virtual Environment**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### **Step 3: Install Dependencies**
```bash
# Python packages
pip install requests pandas google-cloud-bigquery db-dtypes scikit-learn matplotlib seaborn plotly

# Node.js packages (for Prisma APIs)
npm install @prisma/client
npx prisma generate
```

### **Step 4: Configure Google Cloud**
```bash
# Authenticate
gcloud auth application-default login

# Set project
gcloud config set project dwm-ccp-478012

# Create BigQuery dataset
bq mk --location=US heart_disease_warehouse
```

### **Step 5: Start Prisma API Server**
```bash
# Seed database with LLM-generated data
npx prisma db seed

# Start API server
npm run dev
# Server runs at http://localhost:3000
```

### **Step 6: Run ETL Pipeline**
```bash
# Open Jupyter Notebook
jupyter notebook main.ipynb

# Execute all cells (Cell ‚Üí Run All)
# Watch for successful table creation messages
```

### **Step 7: Verify Data Load**
```bash
# Check table row counts
bq query --use_legacy_sql=false '
SELECT 
  "dim_patient" AS table_name, COUNT(*) AS rows FROM `heart_disease_warehouse.dim_patient`
UNION ALL
SELECT "dim_hospital", COUNT(*) FROM `heart_disease_warehouse.dim_hospital`
UNION ALL
SELECT "dim_date", COUNT(*) FROM `heart_disease_warehouse.dim_date`
UNION ALL
SELECT "dim_disease", COUNT(*) FROM `heart_disease_warehouse.dim_disease`
UNION ALL
SELECT "fact_visits", COUNT(*) FROM `heart_disease_warehouse.fact_visits`
UNION ALL
SELECT "fact_labs", COUNT(*) FROM `heart_disease_warehouse.fact_labs`
'

# Expected output:
# dim_patient:  520
# dim_hospital: 12
# dim_date:     2,557
# dim_disease:  3
# fact_visits:  1,345
# fact_labs:    500
```

### **Step 8: Open Dashboard**
```bash
# Dashboard is automatically generated as HTML
open FINAL_Heart_Disease_Dashboard.html
# Or: python -m http.server 8000
# Then open http://localhost:8000/FINAL_Heart_Disease_Dashboard.html
```

---

## üõ†Ô∏è Technologies Used

| Category | Technology | Purpose |
|----------|-----------|---------|
| **Data Sources** | Prisma ORM + PostgreSQL | OLTP systems simulation |
| **Data Generation** | GPT-4 / Claude | Realistic synthetic healthcare data |
| **ETL** | Python 3.8+ | Data extraction, transformation |
| **Data Warehouse** | Google BigQuery | Cloud-native columnar storage |
| **Data Modeling** | Star Schema | Dimensional modeling (Kimball) |
| **Machine Learning** | scikit-learn | Classification, clustering |
| **Visualization** | Plotly, Matplotlib | Interactive dashboards |
| **Version Control** | Git + GitHub | Code management |
| **Documentation** | Markdown, Jupyter | Technical documentation |

---

## üìä Business Intelligence Outputs

### **1. Executive Dashboard**
- 6 KPI cards (real-time metrics)
- Interactive filters by hospital, age group, risk level
- Drill-down from summary to patient-level details

### **2. Clinical Decision Support**
- Patient risk heat map (age vs predicted risk)
- Hospital performance benchmarking
- Lab abnormality trends over time

### **3. Operational Reports**
- Daily census by hospital and severity
- Weekly lab turnaround time analysis
- Monthly cost variance by disease category

### **4. Predictive Analytics**
- 30-day readmission risk scores
- Patient deterioration alerts (ML-powered)
- Resource demand forecasting

---

## üîê Data Governance

### **Security Measures**
- Row-level security in BigQuery (patient data anonymization)
- Role-based access control (RBAC)
- Audit logging enabled for all queries

### **Compliance**
- HIPAA-compliant data handling (de-identified data)
- GDPR considerations (right to erasure implemented)
- Data retention policy (7 years)

---

## üöÄ Future Enhancements

1. **Real-Time Streaming**: Integrate Apache Kafka for live EHR feeds
2. **Advanced ML**: Implement LSTM for time-series prediction of patient decline
3. **NLP Integration**: Extract insights from unstructured clinical notes
4. **Mobile App**: React Native app for doctors to access risk scores
5. **Federated Learning**: Multi-hospital collaborative model training

---

## üìÑ License

This project is created for academic purposes under NED University guidelines.


**Last Updated**: November 2025  
**Version**: 1.0.0
